---
category: installations
title: MPulse
short_title: MPulse
tagline: Interactive climate installation giving Mesa a voice
year: 2025
image: mpulse.png
demo: mpulse.gif
award: "ASU Remix Community Impact Award"
award_line: "ASU Remix Community Impact Award"
features:
  - Community Impact Award at ASU Tech for Change: Remix the Future
  - Interactive heat map of Mesa exploring climate inequality and urban cooling zones
  - Kinect body tracking for real-time user interaction on ASU's large-format MIX Center display
  - Anthropomorphic city narrative voiced with AI via ElevenLabs
  - Built with TouchDesigner, Kinect, Blender, Rhino, OpenTopography, and Adobe Photoshop
tech: Built with TouchDesigner and Kinect for real-time body tracking and interaction. 3D terrain generated from OpenTopography data, modeled in Blender and Rhino. AI voice synthesis via ElevenLabs. Deployed on ASU MIX Center's large-format production display.
links:
  - label: ASU News Coverage
    url: https://news.asu.edu/b/20251028-asu-students-mesa-community-remix-future-civic-impact
  - label: Instagram
    url: https://www.instagram.com/p/DQE8XhIjp0a/
---

What would happen if a city could talk? MPulse gave the city of Mesa a voice to vent about heat inequality and the solutions that can give it a new pulse.

The installation was built for ASU's Tech for Change: Remix the Future, where it received the Community Impact Award. Displayed on the large-format production display at the ASU MIX Center, MPulse invites users to interact with Mesa as a living organism, starting from where they stand at the MIX Center and expanding outward into the city.

Users explore an interactive heat map of Mesa that reveals danger zones, areas of relative coolness, and how the MIX Center itself is situated within that landscape. The piece transforms climate data into something tangible and immediate, bridging the divide between people and the city they inhabit.

We were inspired by the concept of anthropomorphism—the question of how we could connect humans to their city—and by real stories of Mesa shared by ReMix mentors. The city's voice was synthesized using AI via ElevenLabs, and the terrain was generated from OpenTopography data, modeled in Blender and Rhino, and driven by real-time Kinect body tracking through TouchDesigner.

Built with Sam Ravi, Mikale Kaminer, Corey O'Brien, Jazmin Goodwin, and Vishva Doshi.
